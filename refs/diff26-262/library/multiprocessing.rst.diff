--- rest26/library/multiprocessing.rst	2008-12-19 16:58:10.000000000 +0900
+++ rest262/library/multiprocessing.rst	2009-04-07 00:06:53.000000000 +0900
@@ -12,76 +12,118 @@
 
 :mod:`multiprocessing` is a package that supports spawning processes using an
 API similar to the :mod:`threading` module.  The :mod:`multiprocessing` package
 offers both local and remote concurrency, effectively side-stepping the
 :term:`Global Interpreter Lock` by using subprocesses instead of threads.  Due
 to this, the :mod:`multiprocessing` module allows the programmer to fully
 leverage multiple processors on a given machine.  It runs on both Unix and
 Windows.
 
 .. warning::
 
     Some of this package's functionality requires a functioning shared semaphore
-    implementation on the host operating system. Without one, the 
-    :mod:`multiprocessing.synchronize` module will be disabled, and attempts to 
-    import it will result in an :exc:`ImportError`. See 
+    implementation on the host operating system. Without one, the
+    :mod:`multiprocessing.synchronize` module will be disabled, and attempts to
+    import it will result in an :exc:`ImportError`. See
     :issue:`3770` for additional information.
 
+.. note::
+
+    Functionality within this package requires that the ``__main__`` method be
+    importable by the children. This is covered in :ref:`multiprocessing-programming`
+    however it is worth pointing out here. This means that some examples, such
+    as the :class:`multiprocessing.Pool` examples will not work in the
+    interactive interpreter. For example::
+
+        >>> from multiprocessing import Pool
+        >>> p = Pool(5)
+        >>> def f(x):
+        ...     return x*x
+        ...
+        >>> p.map(f, [1,2,3])
+        Process PoolWorker-1:
+        Process PoolWorker-2:
+        Traceback (most recent call last):
+        Traceback (most recent call last):
+        AttributeError: 'module' object has no attribute 'f'
+        AttributeError: 'module' object has no attribute 'f'
+        AttributeError: 'module' object has no attribute 'f'
+
+
 The :class:`Process` class
 ~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 In :mod:`multiprocessing`, processes are spawned by creating a :class:`Process`
 object and then calling its :meth:`~Process.start` method.  :class:`Process`
 follows the API of :class:`threading.Thread`.  A trivial example of a
 multiprocess program is ::
 
-   from multiprocessing import Process
+    from multiprocessing import Process
 
-   def f(name):
-       print 'hello', name
+    def f(name):
+        print 'hello', name
 
-   if __name__ == '__main__':
-       p = Process(target=f, args=('bob',))
-       p.start()
-       p.join()
+    if __name__ == '__main__':
+        p = Process(target=f, args=('bob',))
+        p.start()
+        p.join()
+
+To show the individual process IDs involved, here is an expanded example::
+
+    from multiprocessing import Process
+    import os
 
-Here the function ``f`` is run in a child process.
+    def info(title):
+        print title
+        print 'module name:', __name__
+        print 'parent process:', os.getppid()
+        print 'process id:', os.getpid()
+
+    def f(name):
+        info('function f')
+        print 'hello', name
+
+    if __name__ == '__main__':
+        info('main line')
+        p = Process(target=f, args=('bob',))
+        p.start()
+        p.join()
 
 For an explanation of why (on Windows) the ``if __name__ == '__main__'`` part is
 necessary, see :ref:`multiprocessing-programming`.
 
 
 
 Exchanging objects between processes
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 :mod:`multiprocessing` supports two types of communication channel between
 processes:
 
 **Queues**
 
    The :class:`Queue` class is a near clone of :class:`Queue.Queue`.  For
    example::
 
       from multiprocessing import Process, Queue
 
       def f(q):
           q.put([42, None, 'hello'])
 
-       if __name__ == '__main__':
-           q = Queue()
-           p = Process(target=f, args=(q,))
-           p.start()
-           print q.get()    # prints "[42, None, 'hello']"
-           p.join()
+      if __name__ == '__main__':
+          q = Queue()
+          p = Process(target=f, args=(q,))
+          p.start()
+          print q.get()    # prints "[42, None, 'hello']"
+          p.join()
 
    Queues are thread and process safe.
 
 **Pipes**
 
    The :func:`Pipe` function returns a pair of connection objects connected by a
    pipe which by default is duplex (two-way).  For example::
 
       from multiprocessing import Process, Pipe
 
       def f(conn):
           conn.send([42, None, 'hello'])
@@ -225,25 +267,25 @@
 processes.  It has methods which allows tasks to be offloaded to the worker
 processes in a few different ways.
 
 For example::
 
    from multiprocessing import Pool
 
    def f(x):
        return x*x
 
    if __name__ == '__main__':
        pool = Pool(processes=4)              # start 4 worker processes
-       result = pool.applyAsync(f, [10])     # evaluate "f(10)" asynchronously
+       result = pool.apply_async(f, [10])     # evaluate "f(10)" asynchronously
        print result.get(timeout=1)           # prints "100" unless your computer is *very* slow
        print pool.map(f, range(10))          # prints "[0, 1, 4,..., 81]"
 
 
 Reference
 ---------
 
 The :mod:`multiprocessing` package mostly replicates the API of the
 :mod:`threading` module.
 
 
 :class:`Process` and exceptions
@@ -298,34 +340,34 @@
 
       A process cannot join itself because this would cause a deadlock.  It is
       an error to attempt to join a process before it has been started.
 
    .. attribute:: name
 
       The process's name.
 
       The name is a string used for identification purposes only.  It has no
       semantics.  Multiple processes may be given the same name.  The initial
       name is set by the constructor.
 
-   .. method:: is_alive()
+   .. method:: is_alive
 
       Return whether the process is alive.
 
       Roughly, a process object is alive from the moment the :meth:`start`
       method returns until the child process terminates.
 
    .. attribute:: daemon
 
-      The process's daemon flag, a Boolean value.  This must be called before
+      The process's daemon flag, a Boolean value.  This must be set before
       :meth:`start` is called.
 
       The initial value is inherited from the creating process.
 
       When a process exits, it attempts to terminate all of its daemonic child
       processes.
 
       Note that a daemonic process is not allowed to create child processes.
       Otherwise a daemonic process would leave its children orphaned if it gets
       terminated when its parent process exits.
 
    In addition to the  :class:`Threading.Thread` API, :class:`Process` objects
@@ -369,26 +411,26 @@
          If this method is used when the associated process is using a pipe or
          queue then the pipe or queue is liable to become corrupted and may
          become unusable by other process.  Similarly, if the process has
          acquired a lock or semaphore etc. then terminating it is liable to
          cause other processes to deadlock.
 
    Note that the :meth:`start`, :meth:`join`, :meth:`is_alive` and
    :attr:`exit_code` methods should only be called by the process that created
    the process object.
 
    Example usage of some of the methods of :class:`Process`::
 
-       >>> import processing, time, signal
-       >>> p = processing.Process(target=time.sleep, args=(1000,))
+       >>> import multiprocessing, time, signal
+       >>> p = multiprocessing.Process(target=time.sleep, args=(1000,))
        >>> print p, p.is_alive()
        <Process(Process-1, initial)> False
        >>> p.start()
        >>> print p, p.is_alive()
        <Process(Process-1, started)> True
        >>> p.terminate()
        >>> print p, p.is_alive()
        <Process(Process-1, stopped[SIGTERM])> False
        >>> p.exitcode == -signal.SIGTERM
        True
 
 
@@ -492,25 +534,25 @@
    .. method:: empty()
 
       Return ``True`` if the queue is empty, ``False`` otherwise.  Because of
       multithreading/multiprocessing semantics, this is not reliable.
 
    .. method:: full()
 
       Return ``True`` if the queue is full, ``False`` otherwise.  Because of
       multithreading/multiprocessing semantics, this is not reliable.
 
    .. method:: put(item[, block[, timeout]])
 
-      Put item into the queue.  If the optional argument *block* is ``True`` 
+      Put item into the queue.  If the optional argument *block* is ``True``
       (the default) and *timeout* is ``None`` (the default), block if necessary until
       a free slot is available.  If *timeout* is a positive number, it blocks at
       most *timeout* seconds and raises the :exc:`Queue.Full` exception if no
       free slot was available within that time.  Otherwise (*block* is
       ``False``), put an item on the queue if a free slot is immediately
       available, else raise the :exc:`Queue.Full` exception (*timeout* is
       ignored in that case).
 
    .. method:: put_nowait(item)
 
       Equivalent to ``put(item, False)``.
 
@@ -808,43 +850,46 @@
    A bounded semaphore object: a clone of :class:`threading.Semaphore`.
 
 .. note::
 
    The :meth:`acquire` method of :class:`BoundedSemaphore`, :class:`Lock`,
    :class:`RLock` and :class:`Semaphore` has a timeout parameter not supported
    by the equivalents in :mod:`threading`.  The signature is
    ``acquire(block=True, timeout=None)`` with keyword parameters being
    acceptable.  If *block* is ``True`` and *timeout* is not ``None`` then it
    specifies a timeout in seconds.  If *block* is ``False`` then *timeout* is
    ignored.
 
+   Note that on OS/X ``sem_timedwait`` is unsupported, so timeout arguments
+   for these will be ignored.
+
 .. note::
 
    If the SIGINT signal generated by Ctrl-C arrives while the main thread is
    blocked by a call to :meth:`BoundedSemaphore.acquire`, :meth:`Lock.acquire`,
    :meth:`RLock.acquire`, :meth:`Semaphore.acquire`, :meth:`Condition.acquire`
    or :meth:`Condition.wait` then the call will be immediately interrupted and
    :exc:`KeyboardInterrupt` will be raised.
 
    This differs from the behaviour of :mod:`threading` where SIGINT will be
    ignored while the equivalent blocking calls are in progress.
 
 
 Shared :mod:`ctypes` Objects
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 It is possible to create shared objects using shared memory which can be
 inherited by child processes.
 
-.. function:: Value(typecode_or_type[, *args, lock]])
+.. function:: Value(typecode_or_type, *args[, lock])
 
    Return a :mod:`ctypes` object allocated from shared memory.  By default the
    return value is actually a synchronized wrapper for the object.
 
    *typecode_or_type* determines the type of the returned object: it is either a
    ctypes type or a one character typecode of the kind used by the :mod:`array`
    module.  *\*args* is passed on to the constructor for the type.
 
    If *lock* is ``True`` (the default) then a new lock object is created to
    synchronize access to the value.  If *lock* is a :class:`Lock` or
    :class:`RLock` object then that will be used to synchronize access to the
    value.  If *lock* is ``False`` then access to the returned object will not be
@@ -865,25 +910,25 @@
    Otherwise, *size_or_initializer* is a sequence which is used to initialize
    the array and whose length determines the length of the array.
 
    If *lock* is ``True`` (the default) then a new lock object is created to
    synchronize access to the value.  If *lock* is a :class:`Lock` or
    :class:`RLock` object then that will be used to synchronize access to the
    value.  If *lock* is ``False`` then access to the returned object will not be
    automatically protected by a lock, so it will not necessarily be
    "process-safe".
 
    Note that *lock* is a keyword only argument.
 
-   Note that an array of :data:`ctypes.c_char` has *value* and *rawvalue*
+   Note that an array of :data:`ctypes.c_char` has *value* and *raw*
    attributes which allow one to use it to store and retrieve strings.
 
 
 The :mod:`multiprocessing.sharedctypes` module
 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
 
 .. module:: multiprocessing.sharedctypes
    :synopsis: Allocate ctypes objects from shared memory.
 
 The :mod:`multiprocessing.sharedctypes` module provides functions for allocating
 :mod:`ctypes` objects from shared memory which can be inherited by child
 processes.
@@ -908,35 +953,35 @@
    array and whose length determines the length of the array.
 
    Note that setting and getting an element is potentially non-atomic -- use
    :func:`Array` instead to make sure that access is automatically synchronized
    using a lock.
 
 .. function:: RawValue(typecode_or_type, *args)
 
    Return a ctypes object allocated from shared memory.
 
    *typecode_or_type* determines the type of the returned object: it is either a
    ctypes type or a one character typecode of the kind used by the :mod:`array`
-   module.  */*args* is passed on to the constructor for the type.
+   module.  *\*args* is passed on to the constructor for the type.
 
    Note that setting and getting the value is potentially non-atomic -- use
    :func:`Value` instead to make sure that access is automatically synchronized
    using a lock.
 
-   Note that an array of :data:`ctypes.c_char` has ``value`` and ``rawvalue``
+   Note that an array of :data:`ctypes.c_char` has ``value`` and ``raw``
    attributes which allow one to use it to store and retrieve strings -- see
    documentation for :mod:`ctypes`.
 
-.. function:: Array(typecode_or_type, size_or_initializer[, *args[, lock]])
+.. function:: Array(typecode_or_type, size_or_initializer, *args[, lock])
 
    The same as :func:`RawArray` except that depending on the value of *lock* a
    process-safe synchronization wrapper may be returned instead of a raw ctypes
    array.
 
    If *lock* is ``True`` (the default) then a new lock object is created to
    synchronize access to the value.  If *lock* is a :class:`Lock` or
    :class:`RLock` object then that will be used to synchronize access to the
    value.  If *lock* is ``False`` then access to the returned object will not be
    automatically protected by a lock, so it will not necessarily be
    "process-safe".
 
@@ -1080,24 +1125,45 @@
 
       Start a subprocess to start the manager.
 
    .. method:: serve_forever()
 
       Run the server in the current process.
 
    .. method:: from_address(address, authkey)
 
       A class method which creates a manager object referring to a pre-existing
       server process which is using the given address and authentication key.
 
+   .. method:: get_server()
+
+      Returns a :class:`Server` object which represents the actual server under
+      the control of the Manager. The :class:`Server` object supports the
+      :meth:`serve_forever` method:
+
+      >>> from multiprocessing.managers import BaseManager
+      >>> m = BaseManager(address=('', 50000), authkey='abc'))
+      >>> server = m.get_server()
+      >>> s.serve_forever()
+
+      :class:`Server` additionally have an :attr:`address` attribute.
+
+   .. method:: connect()
+
+      Connect a local manager object to a remote manager process:
+
+      >>> from multiprocessing.managers import BaseManager
+      >>> m = BaseManager(address='127.0.0.1', authkey='abc))
+      >>> m.connect()
+
    .. method:: shutdown()
 
       Stop the process used by the manager.  This is only available if
       :meth:`start` has been used to start the server process.
 
       This can be called multiple times.
 
    .. method:: register(typeid[, callable[, proxytype[, exposed[, method_to_typeid[, create_method]]]]])
 
       A classmethod which can be used for registering a type or callable with
       the manager class.
 
@@ -1220,25 +1286,25 @@
    >>> Global = manager.Namespace()
    >>> Global.x = 10
    >>> Global.y = 'hello'
    >>> Global._z = 12.3    # this is an attribute of the proxy
    >>> print Global
    Namespace(x=10, y='hello')
 
 
 Customized managers
 >>>>>>>>>>>>>>>>>>>
 
 To create one's own manager, one creates a subclass of :class:`BaseManager` and
-use the :meth:`~BaseManager.resgister` classmethod to register new types or
+use the :meth:`~BaseManager.register` classmethod to register new types or
 callables with the manager class.  For example::
 
    from multiprocessing.managers import BaseManager
 
    class MathsClass(object):
        def add(self, x, y):
            return x + y
        def mul(self, x, y):
            return x * y
 
    class MyManager(BaseManager):
        pass
@@ -1258,50 +1324,72 @@
 
 It is possible to run a manager server on one machine and have clients use it
 from other machines (assuming that the firewalls involved allow it).
 
 Running the following commands creates a server for a single shared queue which
 remote clients can access::
 
    >>> from multiprocessing.managers import BaseManager
    >>> import Queue
    >>> queue = Queue.Queue()
    >>> class QueueManager(BaseManager): pass
    ...
-   >>> QueueManager.register('getQueue', callable=lambda:queue)
+   >>> QueueManager.register('get_queue', callable=lambda:queue)
    >>> m = QueueManager(address=('', 50000), authkey='abracadabra')
-   >>> m.serveForever()
+   >>> s = m.get_server()
+   >>> s.serveForever()
 
 One client can access the server as follows::
 
    >>> from multiprocessing.managers import BaseManager
    >>> class QueueManager(BaseManager): pass
    ...
-   >>> QueueManager.register('getQueue')
-   >>> m = QueueManager.from_address(address=('foo.bar.org', 50000),
-   >>> authkey='abracadabra')
-   >>> queue = m.getQueue()
+   >>> QueueManager.register('get_queue')
+   >>> m = QueueManager(address=('foo.bar.org', 50000), authkey='abracadabra')
+   >>> m.connect()
+   >>> queue = m.get_queue()
    >>> queue.put('hello')
 
 Another client can also use it::
 
    >>> from multiprocessing.managers import BaseManager
    >>> class QueueManager(BaseManager): pass
    ...
    >>> QueueManager.register('getQueue')
    >>> m = QueueManager.from_address(address=('foo.bar.org', 50000), authkey='abracadabra')
    >>> queue = m.getQueue()
    >>> queue.get()
    'hello'
 
+Local processes can also access that queue, using the code from above on the
+client to access it remotely::
+
+    >>> from multiprocessing import Process, Queue
+    >>> from multiprocessing.managers import BaseManager
+    >>> class Worker(Process):
+    ...     def __init__(self, q):
+    ...         self.q = q
+    ...         super(Worker, self).__init__()
+    ...     def run(self):
+    ...         self.q.put('local hello')
+    ...
+    >>> queue = Queue()
+    >>> w = Worker(queue)
+    >>> w.start()
+    >>> class QueueManager(BaseManager): pass
+    ...
+    >>> QueueManager.register('get_queue', callable=lambda: queue)
+    >>> m = QueueManager(address=('', 50000), authkey='abracadabra')
+    >>> s = m.get_server()
+    >>> s.serve_forever()
 
 Proxy Objects
 ~~~~~~~~~~~~~
 
 A proxy is an object which *refers* to a shared object which lives (presumably)
 in a different process.  The shared object is said to be the *referent* of the
 proxy.  Multiple proxy objects may have the same referent.
 
 A proxy object has methods which invoke corresponding methods of its referent
 (although not every method of the referent will necessarily be available through
 the proxy).  A proxy can usually be used in most of the same ways that its
 referent can::
@@ -1341,63 +1429,63 @@
    The proxy types in :mod:`multiprocessing` do nothing to support comparisons
    by value.  So, for instance, ::
 
        manager.list([1,2,3]) == [1,2,3]
 
    will return ``False``.  One should just use a copy of the referent instead
    when making comparisons.
 
 .. class:: BaseProxy
 
    Proxy objects are instances of subclasses of :class:`BaseProxy`.
 
-   .. method:: _call_method(methodname[, args[, kwds]])
+   .. method:: _callmethod(methodname[, args[, kwds]])
 
       Call and return the result of a method of the proxy's referent.
 
       If ``proxy`` is a proxy whose referent is ``obj`` then the expression ::
 
-         proxy._call_method(methodname, args, kwds)
+         proxy._callmethod(methodname, args, kwds)
 
       will evaluate the expression ::
 
          getattr(obj, methodname)(*args, **kwds)
 
       in the manager's process.
 
       The returned value will be a copy of the result of the call or a proxy to
       a new shared object -- see documentation for the *method_to_typeid*
       argument of :meth:`BaseManager.register`.
 
       If an exception is raised by the call, then then is re-raised by
-      :meth:`_call_method`.  If some other exception is raised in the manager's
+      :meth:`_callmethod`.  If some other exception is raised in the manager's
       process then this is converted into a :exc:`RemoteError` exception and is
-      raised by :meth:`_call_method`.
+      raised by :meth:`_callmethod`.
 
       Note in particular that an exception will be raised if *methodname* has
       not been *exposed*
 
-      An example of the usage of :meth:`_call_method`::
+      An example of the usage of :meth:`_callmethod`::
 
          >>> l = manager.list(range(10))
-         >>> l._call_method('__len__')
+         >>> l._callmethod('__len__')
          10
-         >>> l._call_method('__getslice__', (2, 7))   # equiv to `l[2:7]`
+         >>> l._callmethod('__getslice__', (2, 7))   # equiv to `l[2:7]`
          [2, 3, 4, 5, 6]
-         >>> l._call_method('__getitem__', (20,))     # equiv to `l[20]`
+         >>> l._callmethod('__getitem__', (20,))     # equiv to `l[20]`
          Traceback (most recent call last):
          ...
          IndexError: list index out of range
 
-   .. method:: _get_value()
+   .. method:: _getvalue()
 
       Return a copy of the referent.
 
       If the referent is unpicklable then this will raise an exception.
 
    .. method:: __repr__
 
       Return a representation of the proxy object.
 
    .. method:: __str__
 
       Return the representation of the referent.
@@ -1440,26 +1528,26 @@
 
    .. method:: apply_async(func[, args[, kwds[, callback]]])
 
       A variant of the :meth:`apply` method which returns a result object.
 
       If *callback* is specified then it should be a callable which accepts a
       single argument.  When the result becomes ready *callback* is applied to
       it (unless the call failed).  *callback* should complete immediately since
       otherwise the thread which handles the results will get blocked.
 
    .. method:: map(func, iterable[, chunksize])
 
-      A parallel equivalent of the :func:`map` builtin function.  It blocks till
-      the result is ready.
+      A parallel equivalent of the :func:`map` builtin function (it supports only
+      one *iterable* argument though).  It blocks till the result is ready.
 
       This method chops the iterable into a number of chunks which it submits to
       the process pool as separate tasks.  The (approximate) size of these
       chunks can be specified by setting *chunksize* to a positive integer.
 
    .. method:: map_async(func, iterable[, chunksize[, callback]])
 
       A variant of the :meth:`map` method which returns a result object.
 
       If *callback* is specified then it should be a callable which accepts a
       single argument.  When the result becomes ready *callback* is applied to
       it (unless the call failed).  *callback* should complete immediately since
@@ -1498,25 +1586,25 @@
 
    .. method:: join()
 
       Wait for the worker processes to exit.  One must call :meth:`close` or
       :meth:`terminate` before using :meth:`join`.
 
 
 .. class:: AsyncResult
 
    The class of the result returned by :meth:`Pool.apply_async` and
    :meth:`Pool.map_async`.
 
-   .. method:: get([timeout)
+   .. method:: get([timeout])
 
       Return the result when it arrives.  If *timeout* is not ``None`` and the
       result does not arrive within *timeout* seconds then
       :exc:`multiprocessing.TimeoutError` is raised.  If the remote call raised
       an exception then that exception will be reraised by :meth:`get`.
 
    .. method:: wait([timeout])
 
       Wait until the result is available or until *timeout* seconds pass.
 
    .. method:: ready()
 
@@ -1528,36 +1616,36 @@
       raise :exc:`AssertionError` if the result is not ready.
 
 The following example demonstrates the use of a pool::
 
    from multiprocessing import Pool
 
    def f(x):
        return x*x
 
    if __name__ == '__main__':
        pool = Pool(processes=4)              # start 4 worker processes
 
-       result = pool.applyAsync(f, (10,))    # evaluate "f(10)" asynchronously
+       result = pool.apply_async(f, (10,))    # evaluate "f(10)" asynchronously
        print result.get(timeout=1)           # prints "100" unless your computer is *very* slow
 
        print pool.map(f, range(10))          # prints "[0, 1, 4,..., 81]"
 
        it = pool.imap(f, range(10))
        print it.next()                       # prints "0"
        print it.next()                       # prints "1"
        print it.next(timeout=1)              # prints "4" unless your computer is *very* slow
 
        import time
-       result = pool.applyAsync(time.sleep, (10,))
+       result = pool.apply_async(time.sleep, (10,))
        print result.get(timeout=1)           # raises TimeoutError
 
 
 .. _multiprocessing-listeners-clients:
 
 Listeners and Clients
 ~~~~~~~~~~~~~~~~~~~~~
 
 .. module:: multiprocessing.connection
    :synopsis: API for dealing with sockets.
 
 Usually message passing between processes is done using queues or by using
@@ -1600,24 +1688,30 @@
    *authkey* or ``current_process().authkey)`` if *authkey* is ``None``.
    If authentication fails then :exc:`AuthenticationError` is raised.  See
    :ref:`multiprocessing-auth-keys`.
 
 .. class:: Listener([address[, family[, backlog[, authenticate[, authkey]]]]])
 
    A wrapper for a bound socket or Windows named pipe which is 'listening' for
    connections.
 
    *address* is the address to be used by the bound socket or named pipe of the
    listener object.
 
+   .. note::
+
+      If an address of '0.0.0.0' is used, the address will not be a connectable
+      end point on Windows. If you require a connectable end-point,
+      you should use '127.0.0.1'.
+
    *family* is the type of socket (or named pipe) to use.  This can be one of
    the strings ``'AF_INET'`` (for a TCP socket), ``'AF_UNIX'`` (for a Unix
    domain socket) or ``'AF_PIPE'`` (for a Windows named pipe).  Of these only
    the first is guaranteed to be available.  If *family* is ``None`` then the
    family is inferred from the format of *address*.  If *address* is also
    ``None`` then a default is chosen.  This default is the family which is
    assumed to be the fastest available.  See
    :ref:`multiprocessing-address-formats`.  Note that if *family* is
    ``'AF_UNIX'`` and address is ``None`` then the socket will be created in a
    private temporary directory created using :func:`tempfile.mkstemp`.
 
    If the listener object uses a socket then *backlog* (1 by default) is passed
@@ -1713,27 +1807,27 @@
 .. _multiprocessing-address-formats:
 
 Address Formats
 >>>>>>>>>>>>>>>
 
 * An ``'AF_INET'`` address is a tuple of the form ``(hostname, port)`` where
   *hostname* is a string and *port* is an integer.
 
 * An ``'AF_UNIX'`` address is a string representing a filename on the
   filesystem.
 
 * An ``'AF_PIPE'`` address is a string of the form
-   ``r'\\\\.\\pipe\\PipeName'``.  To use :func:`Client` to connect to a named
-   pipe on a remote computer called ServerName* one should use an address of the
-   form ``r'\\\\ServerName\\pipe\\PipeName'`` instead.
+   :samp:`r'\\\\.\\pipe\\{PipeName}'`.  To use :func:`Client` to connect to a named
+   pipe on a remote computer called *ServerName* one should use an address of the
+   form :samp:`r'\\\\{ServerName}\\pipe\\{PipeName}'` instead.
 
 Note that any string beginning with two backslashes is assumed by default to be
 an ``'AF_PIPE'`` address rather than an ``'AF_UNIX'`` address.
 
 
 .. _multiprocessing-auth-keys:
 
 Authentication keys
 ~~~~~~~~~~~~~~~~~~~
 
 When one uses :meth:`Connection.recv`, the data received is automatically
 unpickled.  Unfortunately unpickling data from an untrusted source is a security
@@ -1742,66 +1836,110 @@
 
 An authentication key is a string which can be thought of as a password: once a
 connection is established both ends will demand proof that the other knows the
 authentication key.  (Demonstrating that both ends are using the same key does
 **not** involve sending the key over the connection.)
 
 If authentication is requested but do authentication key is specified then the
 return value of ``current_process().authkey`` is used (see
 :class:`~multiprocessing.Process`).  This value will automatically inherited by
 any :class:`~multiprocessing.Process` object that the current process creates.
 This means that (by default) all processes of a multi-process program will share
 a single authentication key which can be used when setting up connections
-between the themselves.
+between themselves.
 
 Suitable authentication keys can also be generated by using :func:`os.urandom`.
 
 
 Logging
 ~~~~~~~
 
 Some support for logging is available.  Note, however, that the :mod:`logging`
 package does not use process shared locks so it is possible (depending on the
 handler type) for messages from different processes to get mixed up.
 
 .. currentmodule:: multiprocessing
 .. function:: get_logger()
 
    Returns the logger used by :mod:`multiprocessing`.  If necessary, a new one
    will be created.
 
-   When first created the logger has level :data:`logging.NOTSET` and has a
-   handler which sends output to :data:`sys.stderr` using format
-   ``'[%(levelname)s/%(processName)s] %(message)s'``.  (The logger allows use of
-   the non-standard ``'%(processName)s'`` format.)  Message sent to this logger
-   will not by default propagate to the root logger.
+   When first created the logger has level :data:`logging.NOTSET` and no
+   default handler. Messages sent to this logger will not by default propagate
+   to the root logger.
 
    Note that on Windows child processes will only inherit the level of the
    parent process's logger -- any other customization of the logger will not be
    inherited.
 
+.. currentmodule:: multiprocessing
+.. function:: log_to_stderr()
+
+   This function performs a call to :func:`get_logger` but in addition to
+   returning the logger created by get_logger, it adds a handler which sends
+   output to :data:`sys.stderr` using format
+   ``'[%(levelname)s/%(processName)s] %(message)s'``.
+
 Below is an example session with logging turned on::
 
-    >>> import processing, logging
-    >>> logger = processing.getLogger()
+    >>> import multiprocessing, logging
+    >>> logger = multiprocessing.log_to_stderr()
     >>> logger.setLevel(logging.INFO)
     >>> logger.warning('doomed')
     [WARNING/MainProcess] doomed
-    >>> m = processing.Manager()
+    >>> m = multiprocessing.Manager()
     [INFO/SyncManager-1] child process calling self.run()
-    [INFO/SyncManager-1] manager bound to '\\\\.\\pipe\\pyc-2776-0-lj0tfa'
+    [INFO/SyncManager-1] created temp directory /.../pymp-Wh47O_
+    [INFO/SyncManager-1] manager serving at '/.../listener-lWsERs'
     >>> del m
     [INFO/MainProcess] sending shutdown message to manager
     [INFO/SyncManager-1] manager exiting with exitcode 0
 
+In addition to having these two logging functions, the multiprocessing also
+exposes two additional logging level attributes. These are  :const:`SUBWARNING`
+and :const:`SUBDEBUG`. The table below illustrates where theses fit in the
+normal level hierarchy.
+
++----------------+----------------+
+| Level          | Numeric value  |
++================+================+
+| ``SUBWARNING`` | 25             |
++----------------+----------------+
+| ``SUBDEBUG``   | 5              |
++----------------+----------------+
+
+For a full table of logging levels, see the :mod:`logging` module.
+
+These additional logging levels are used primarily for certain debug messages
+within the multiprocessing module. Below is the same example as above, except
+with :const:`SUBDEBUG` enabled::
+
+    >>> import multiprocessing, logging
+    >>> logger = multiprocessing.log_to_stderr()
+    >>> logger.setLevel(multiprocessing.SUBDEBUG)
+    >>> logger.warning('doomed')
+    [WARNING/MainProcess] doomed
+    >>> m = multiprocessing.Manager()
+    [INFO/SyncManager-1] child process calling self.run()
+    [INFO/SyncManager-1] created temp directory /.../pymp-djGBXN
+    [INFO/SyncManager-1] manager serving at '/.../pymp-djGBXN/listener-knBYGe'
+    >>> del m
+    [SUBDEBUG/MainProcess] finalizer calling ...
+    [INFO/MainProcess] sending shutdown message to manager
+    [DEBUG/SyncManager-1] manager received shutdown message
+    [SUBDEBUG/SyncManager-1] calling <Finalize object, callback=unlink, ...
+    [SUBDEBUG/SyncManager-1] finalizer calling <built-in function unlink> ...
+    [SUBDEBUG/SyncManager-1] calling <Finalize object, dead>
+    [SUBDEBUG/SyncManager-1] finalizer calling <function rmtree at 0x5aa730> ...
+    [INFO/SyncManager-1] manager exiting with exitcode 0
 
 The :mod:`multiprocessing.dummy` module
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 .. module:: multiprocessing.dummy
    :synopsis: Dumb wrapper around threading.
 
 :mod:`multiprocessing.dummy` replicates the API of :mod:`multiprocessing` but is
 no more than a wrapper around the :mod:`threading` module.
 
 
 .. _multiprocessing-programming:
@@ -2023,18 +2161,18 @@
 An example of how a pool of worker processes can each run a
 :class:`SimpleHTTPServer.HttpServer` instance while sharing a single listening
 socket.
 
 .. literalinclude:: ../includes/mp_webserver.py
 
 
 Some simple benchmarks comparing :mod:`multiprocessing` with :mod:`threading`:
 
 .. literalinclude:: ../includes/mp_benchmarks.py
 
 An example/demo of how to use the :class:`managers.SyncManager`, :class:`Process`
-and others to build a system which can distribute processes and work via a 
+and others to build a system which can distribute processes and work via a
 distributed queue to a "cluster" of machines on a network, accessible via SSH.
 You will need to have private key authentication for all hosts configured for
 this to work.
 
 .. literalinclude:: ../includes/mp_distributing.py
