@@ -19,25 +19,25 @@
 Windows.
 
 .. warning::
 
     Some of this package's functionality requires a functioning shared semaphore
     implementation on the host operating system. Without one, the
     :mod:`multiprocessing.synchronize` module will be disabled, and attempts to
     import it will result in an :exc:`ImportError`. See
     :issue:`3770` for additional information.
 
 .. note::
 
-    Functionality within this package requires that the ``__main__`` method be
+    Functionality within this package requires that the ``__main__`` module be
     importable by the children. This is covered in :ref:`multiprocessing-programming`
     however it is worth pointing out here. This means that some examples, such
     as the :class:`multiprocessing.Pool` examples will not work in the
     interactive interpreter. For example::
 
         >>> from multiprocessing import Pool
         >>> p = Pool(5)
         >>> def f(x):
         ...     return x*x
         ...
         >>> p.map(f, [1,2,3])
         Process PoolWorker-1:
@@ -207,25 +207,25 @@
 
           print num.value
           print arr[:]
 
    will print ::
 
       3.1415927
       [0, -1, -2, -3, -4, -5, -6, -7, -8, -9]
 
    The ``'d'`` and ``'i'`` arguments used when creating ``num`` and ``arr`` are
    typecodes of the kind used by the :mod:`array` module: ``'d'`` indicates a
    double precision float and ``'i'`` indicates a signed integer.  These shared
-   objects will be process and thread safe.
+   objects will be process and thread-safe.
 
    For more flexibility in using shared memory one can use the
    :mod:`multiprocessing.sharedctypes` module which supports the creation of
    arbitrary ctypes objects allocated from shared memory.
 
 **Server process**
 
    A manager object returned by :func:`Manager` controls a server process which
    holds Python objects and allows other processes to manipulate them using
    proxies.
 
    A manager returned by :func:`Manager` will support types :class:`list`,
@@ -367,25 +367,25 @@
       The process's daemon flag, a Boolean value.  This must be set before
       :meth:`start` is called.
 
       The initial value is inherited from the creating process.
 
       When a process exits, it attempts to terminate all of its daemonic child
       processes.
 
       Note that a daemonic process is not allowed to create child processes.
       Otherwise a daemonic process would leave its children orphaned if it gets
       terminated when its parent process exits. Additionally, these are **not**
       Unix daemons or services, they are normal processes that will be
-      terminated (and not joined) if non-dameonic processes have exited.
+      terminated (and not joined) if non-daemonic processes have exited.
 
    In addition to the  :class:`Threading.Thread` API, :class:`Process` objects
    also support the following attributes and methods:
 
    .. attribute:: pid
 
       Return the process ID.  Before the process is spawned, this will be
       ``None``.
 
    .. attribute:: exitcode
 
       The child's exit code.  This will be ``None`` if the process has not yet
@@ -712,25 +712,26 @@
 strings.  They can be thought of as message oriented connected sockets.
 
 Connection objects usually created using :func:`Pipe` -- see also
 :ref:`multiprocessing-listeners-clients`.
 
 .. class:: Connection
 
    .. method:: send(obj)
 
       Send an object to the other end of the connection which should be read
       using :meth:`recv`.
 
-      The object must be picklable.
+      The object must be picklable.  Very large pickles (approximately 32 MB+,
+      though it depends on the OS) may raise a ValueError exception.
 
    .. method:: recv()
 
       Return an object sent from the other end of the connection using
       :meth:`send`.  Raises :exc:`EOFError` if there is nothing left to receive
       and the other end was closed.
 
    .. method:: fileno()
 
       Returns the file descriptor or handle used by the connection.
 
    .. method:: close()
@@ -744,25 +745,27 @@
       Return whether there is any data available to be read.
 
       If *timeout* is not specified then it will return immediately.  If
       *timeout* is a number then this specifies the maximum time in seconds to
       block.  If *timeout* is ``None`` then an infinite timeout is used.
 
    .. method:: send_bytes(buffer[, offset[, size]])
 
       Send byte data from an object supporting the buffer interface as a
       complete message.
 
       If *offset* is given then data is read from that position in *buffer*.  If
-      *size* is given then that many bytes will be read from buffer.
+      *size* is given then that many bytes will be read from buffer.  Very large
+      buffers (approximately 32 MB+, though it depends on the OS) may raise a
+      ValueError exception
 
    .. method:: recv_bytes([maxlength])
 
       Return a complete message of byte data sent from the other end of the
       connection as a string.  Raises :exc:`EOFError` if there is nothing left
       to receive and the other end has closed.
 
       If *maxlength* is specified and the message is longer than *maxlength*
       then :exc:`IOError` is raised and the connection will no longer be
       readable.
 
    .. method:: recv_bytes_into(buffer[, offset])
@@ -840,36 +843,42 @@
    ``sem_getvalue()`` is not implemented on that platform).
 
 .. class:: Condition([lock])
 
    A condition variable: a clone of :class:`threading.Condition`.
 
    If *lock* is specified then it should be a :class:`Lock` or :class:`RLock`
    object from :mod:`multiprocessing`.
 
 .. class:: Event()
 
    A clone of :class:`threading.Event`.
+   This method returns the state of the internal semaphore on exit, so it
+   will always return ``True`` except if a timeout is given and the operation
+   times out.
+
+   .. versionchanged:: 2.7
+      Previously, the method always returned ``None``.
 
 .. class:: Lock()
 
    A non-recursive lock object: a clone of :class:`threading.Lock`.
 
 .. class:: RLock()
 
    A recursive lock object: a clone of :class:`threading.RLock`.
 
 .. class:: Semaphore([value])
 
-   A bounded semaphore object: a clone of :class:`threading.Semaphore`.
+   A semaphore object: a clone of :class:`threading.Semaphore`.
 
 .. note::
 
    The :meth:`acquire` method of :class:`BoundedSemaphore`, :class:`Lock`,
    :class:`RLock` and :class:`Semaphore` has a timeout parameter not supported
    by the equivalents in :mod:`threading`.  The signature is
    ``acquire(block=True, timeout=None)`` with keyword parameters being
    acceptable.  If *block* is ``True`` and *timeout* is not ``None`` then it
    specifies a timeout in seconds.  If *block* is ``False`` then *timeout* is
    ignored.
 
    On Mac OS X, ``sem_timedwait`` is unsupported, so calling ``acquire()`` with
@@ -1125,27 +1134,28 @@
 
    Once created one should call :meth:`start` or ``get_server().serve_forever()`` to ensure
    that the manager object refers to a started manager process.
 
    *address* is the address on which the manager process listens for new
    connections.  If *address* is ``None`` then an arbitrary one is chosen.
 
    *authkey* is the authentication key which will be used to check the validity
    of incoming connections to the server process.  If *authkey* is ``None`` then
    ``current_process().authkey``.  Otherwise *authkey* is used and it
    must be a string.
 
-   .. method:: start()
-
-      Start a subprocess to start the manager.
+   .. method:: start([initializer[, initargs]])
+
+      Start a subprocess to start the manager.  If *initializer* is not ``None``
+      then the subprocess will call ``initializer(*initargs)`` when it starts.
 
    .. method:: get_server()
 
       Returns a :class:`Server` object which represents the actual server under
       the control of the Manager. The :class:`Server` object supports the
       :meth:`serve_forever` method::
 
       >>> from multiprocessing.managers import BaseManager
       >>> manager = BaseManager(address=('', 50000), authkey='abc')
       >>> server = manager.get_server()
       >>> server.serve_forever()
 
@@ -1267,24 +1277,42 @@
 
    .. method:: dict()
                dict(mapping)
                dict(sequence)
 
       Create a shared ``dict`` object and return a proxy for it.
 
    .. method:: list()
                list(sequence)
 
       Create a shared ``list`` object and return a proxy for it.
 
+   .. note::
+
+      Modifications to mutable values or items in dict and list proxies will not
+      be propagated through the manager, because the proxy has no way of knowing
+      when its values or items are modified.  To modify such an item, you can
+      re-assign the modified object to the container proxy::
+
+         # create a list proxy and append a mutable object (a dictionary)
+         lproxy = manager.list()
+         lproxy.append({})
+         # now mutate the dictionary
+         d = lproxy[0]
+         d['a'] = 1
+         d['b'] = 2
+         # at this point, the changes to d are not yet synced, but by
+         # reassigning the dictionary, the proxy is notified of the change
+         lproxy[0] = d
+
 
 Namespace objects
 >>>>>>>>>>>>>>>>>
 
 A namespace object has no public methods, but does have writable attributes.
 Its representation shows the values of its attributes.
 
 However, when using a proxy for a namespace object, an attribute beginning with
 ``'_'`` will be an attribute of the proxy and not an attribute of the referent:
 
 .. doctest::
 
@@ -1513,35 +1541,51 @@
 any proxies referring to it.
 
 
 Process Pools
 ~~~~~~~~~~~~~
 
 .. module:: multiprocessing.pool
    :synopsis: Create pools of processes.
 
 One can create a pool of processes which will carry out tasks submitted to it
 with the :class:`Pool` class.
 
-.. class:: multiprocessing.Pool([processes[, initializer[, initargs]]])
+.. class:: multiprocessing.Pool([processes[, initializer[, initargs[, maxtasksperchild]]]])
 
    A process pool object which controls a pool of worker processes to which jobs
    can be submitted.  It supports asynchronous results with timeouts and
    callbacks and has a parallel map implementation.
 
    *processes* is the number of worker processes to use.  If *processes* is
    ``None`` then the number returned by :func:`cpu_count` is used.  If
    *initializer* is not ``None`` then each worker process will call
    ``initializer(*initargs)`` when it starts.
 
+   .. versionadded:: 2.7
+      *maxtasksperchild* is the number of tasks a worker process can complete
+      before it will exit and be replaced with a fresh worker process, to enable
+      unused resources to be freed. The default *maxtasksperchild* is None, which
+      means worker processes will live as long as the pool.
+
+   .. note::
+
+      Worker processes within a :class:`Pool` typically live for the complete
+      duration of the Pool's work queue. A frequent pattern found in other
+      systems (such as Apache, mod_wsgi, etc) to free resources held by
+      workers is to allow a worker within a pool to complete only a set
+      amount of work before being exiting, being cleaned up and a new
+      process spawned to replace the old one. The *maxtasksperchild*
+      argument to the :class:`Pool` exposes this ability to the end user.
+
    .. method:: apply(func[, args[, kwds]])
 
       Equivalent of the :func:`apply` built-in function.  It blocks till the
       result is ready.  Given this blocks, :meth:`apply_async` is better suited
       for performing work in parallel. Additionally, the passed
       in function is only executed in one of the workers of the pool.
 
    .. method:: apply_async(func[, args[, kwds[, callback]]])
 
       A variant of the :meth:`apply` method which returns a result object.
 
       If *callback* is specified then it should be a callable which accepts a
@@ -2189,26 +2233,26 @@
 
 
 Using :class:`Pool`:
 
 .. literalinclude:: ../includes/mp_pool.py
 
 
 Synchronization types like locks, conditions and queues:
 
 .. literalinclude:: ../includes/mp_synchronize.py
 
 
-An showing how to use queues to feed tasks to a collection of worker process and
-collect the results:
+An example showing how to use queues to feed tasks to a collection of worker
+process and collect the results:
 
 .. literalinclude:: ../includes/mp_workers.py
 
 
 An example of how a pool of worker processes can each run a
 :class:`SimpleHTTPServer.HttpServer` instance while sharing a single listening
 socket.
 
 .. literalinclude:: ../includes/mp_webserver.py
 
 
 Some simple benchmarks comparing :mod:`multiprocessing` with :mod:`threading`:
